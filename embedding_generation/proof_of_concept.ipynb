{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import wikipedia\n",
    "import torch\n",
    "from typing import List, Tuple, Union, Optional\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiImageMatcher:\n",
    "    def __init__(self, model_name: str = \"openai/clip-vit-base-patch32\"):\n",
    "        \"\"\"\n",
    "        Initialize the WikiImageMatcher with a CLIP model from Hugging Face.\n",
    "        \n",
    "        Args:\n",
    "            model_name (str): Name of the CLIP model from Hugging Face\n",
    "        \"\"\"\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "        self.model = CLIPModel.from_pretrained(model_name).to(self.device)\n",
    "        self.processor = CLIPProcessor.from_pretrained(model_name)\n",
    "\n",
    "    def clean_wiki_text(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Clean Wikipedia text by removing references, links, and extra whitespace.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Raw Wikipedia text\n",
    "            \n",
    "        Returns:\n",
    "            str: Cleaned text\n",
    "        \"\"\"\n",
    "        # Remove references\n",
    "        text = re.sub(r'\\[\\d+\\]', '', text)\n",
    "        # Remove multiple newlines\n",
    "        text = re.sub(r'\\n+', ' ', text)\n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        return text\n",
    "    \n",
    "    def find_wiki_article(self, query: str) -> Optional[wikipedia.WikipediaPage]:\n",
    "        \"\"\"\n",
    "        Find a Wikipedia article using multiple search strategies.\n",
    "        \n",
    "        Args:\n",
    "            query (str): Article title or search query\n",
    "            \n",
    "        Returns:\n",
    "            Optional[wikipedia.WikipediaPage]: Wikipedia page if found, None otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Strategy 1: Try direct page lookup\n",
    "            try:\n",
    "                return wikipedia.page(query, auto_suggest=False)\n",
    "            except (wikipedia.exceptions.PageError, wikipedia.exceptions.DisambiguationError):\n",
    "                pass\n",
    "\n",
    "            # Strategy 2: Try with auto_suggest\n",
    "            try:\n",
    "                return wikipedia.page(query, auto_suggest=True)\n",
    "            except wikipedia.exceptions.DisambiguationError as e:\n",
    "                # If disambiguation page, try the first suggestion\n",
    "                try:\n",
    "                    return wikipedia.page(e.options[0], auto_suggest=False)\n",
    "                except:\n",
    "                    pass\n",
    "            except wikipedia.exceptions.PageError:\n",
    "                pass\n",
    "\n",
    "            # Strategy 3: Search and use the first result\n",
    "            search_results = wikipedia.search(query, results=5)\n",
    "            if search_results:\n",
    "                try:\n",
    "                    return wikipedia.page(search_results[0], auto_suggest=False)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            # If all strategies fail\n",
    "            return None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching for '{query}': {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def get_article_embedding(self, article_name: str) -> Tuple[Optional[torch.Tensor], Optional[str]]:\n",
    "        \"\"\"\n",
    "        Get CLIP embedding for a Wikipedia article.\n",
    "        \n",
    "        Args:\n",
    "            article_name (str): Name of the Wikipedia article\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[Optional[torch.Tensor], Optional[str]]: \n",
    "                (embedding vector, actual article title) if successful,\n",
    "                (None, None) if failed\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Find the article\n",
    "            page = self.find_wiki_article(article_name)\n",
    "            if page is None:\n",
    "                print(f\"Could not find article: {article_name}\")\n",
    "                return None, None\n",
    "\n",
    "            # Get and clean content\n",
    "            content = self.clean_wiki_text(page.content)\n",
    "            \n",
    "            # Process text through CLIP\n",
    "            with torch.no_grad():\n",
    "                inputs = self.processor(\n",
    "                    text=[content],\n",
    "                    return_tensors=\"pt\",\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=77\n",
    "                )\n",
    "                text_features = self.model.get_text_features(**{k: v.to(self.device) for k, v in inputs.items()})\n",
    "                normalized_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "                \n",
    "            return normalized_features, page.title\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing article '{article_name}': {str(e)}\")\n",
    "            return None, None\n",
    "\n",
    "    \n",
    "    def get_image_embedding(self, image: Union[str, Image.Image]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Get CLIP embedding for an image.\n",
    "        \n",
    "        Args:\n",
    "            image (Union[str, Image.Image]): Either a path to an image or a PIL Image\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Embedding vector for the image\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load image if path is provided\n",
    "            if isinstance(image, str):\n",
    "                image = Image.open(image)\n",
    "                \n",
    "            # Process image through CLIP\n",
    "            with torch.no_grad():\n",
    "                inputs = self.processor(\n",
    "                    images=image,\n",
    "                    return_tensors=\"pt\"\n",
    "                )\n",
    "                image_features = self.model.get_image_features(**{k: v.to(self.device) for k, v in inputs.items()})\n",
    "                \n",
    "            return image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error processing image: {str(e)}\")\n",
    "    \n",
    "    def find_matches(self, \n",
    "                    query_embedding: torch.Tensor,\n",
    "                    article_embeddings: List[Tuple[str, torch.Tensor]],\n",
    "                    num_matches: int = 1) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Find the closest matching articles for a query embedding.\n",
    "        \n",
    "        Args:\n",
    "            query_embedding (torch.Tensor): Embedding vector to match against\n",
    "            article_embeddings (List[Tuple[str, torch.Tensor]]): List of (article_name, embedding) pairs\n",
    "            num_matches (int): Number of matches to return\n",
    "            \n",
    "        Returns:\n",
    "            List[Tuple[str, float]]: List of (article_name, similarity_score) pairs\n",
    "        \"\"\"\n",
    "        similarities = []\n",
    "        \n",
    "        for article_name, article_embedding in article_embeddings:\n",
    "            similarity = torch.nn.functional.cosine_similarity(\n",
    "                query_embedding, article_embedding\n",
    "            ).item()\n",
    "            similarities.append((article_name, similarity))\n",
    "        \n",
    "        # Sort by similarity score in descending order\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        return similarities[:num_matches]\n",
    "\n",
    "# Example usage function\n",
    "def demo_wiki_image_matcher(image_path: str, article_names: List[str], num_matches: int = 1):\n",
    "    \"\"\"\n",
    "    Demonstrate the WikiImageMatcher with example usage.\n",
    "    \"\"\"\n",
    "    matcher = WikiImageMatcher()\n",
    "    \n",
    "    # Get embeddings for all articles\n",
    "    article_embeddings = []\n",
    "    for article_name in article_names:\n",
    "        embedding, actual_title = matcher.get_article_embedding(article_name)\n",
    "        if embedding is not None and actual_title is not None:\n",
    "            article_embeddings.append((actual_title, embedding))\n",
    "        else:\n",
    "            print(f\"Skipping '{article_name}' due to retrieval error\")\n",
    "    \n",
    "    if not article_embeddings:\n",
    "        print(\"No valid articles found to match against\")\n",
    "        return []\n",
    "\n",
    "    # Get embedding for the query image\n",
    "    image_embedding = matcher.get_image_embedding(image_path)\n",
    "    \n",
    "    # Find matches\n",
    "    matches = matcher.find_matches(image_embedding, article_embeddings, num_matches)\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/clkruse/Downloads/astro_test.png'\n",
    "demo_wiki_image_matcher(image_path, [\"Astronaut\", \"Ancient Greek\", \"Roses\", \"Mount Everest\", \"Midjourney\", \"Pink (Color)\"], num_matches=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"facebook/contrastive_search_index\", streaming=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
